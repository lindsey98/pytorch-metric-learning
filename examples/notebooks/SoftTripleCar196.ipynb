{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  1 15:31:33 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 22%   29C    P0    33W / 250W |      0MiB / 12066MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN V             Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 21%   31C    P0    34W / 250W |      0MiB / 12066MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/l/liny/ruofan/pytorch-metric-learning/src')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1, 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_metric_learning.models import bninception\n",
    "from pytorch_metric_learning import samplers\n",
    "from pytorch_metric_learning.datasets.Car196.data_loaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "num_classes = 196\n",
    "hidden_dim = 512\n",
    "centers_per_class = 5\n",
    "result_dir = './log'\n",
    "exp_name = 'Car196'\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = CarsDataset(\n",
    "                        data_dir='pytorch_metric_learning/datasets/Car196/datasets/training/extracted/', \n",
    "                        metas='pytorch_metric_learning/datasets/Car196/datasets/cars_metas/cars_train_annos.mat', \n",
    "                        transform=train_transform,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CarsDataset(\n",
    "                        data_dir='pytorch_metric_learning/datasets/Car196/datasets/testing/extracted/', \n",
    "                        metas='pytorch_metric_learning/datasets/Car196/datasets/cars_metas/cars_test_annos_withlabels.mat', \n",
    "                        transform=test_transform,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = samplers.MPerClassSampler(train_data.target, \n",
    "                                    m=5, \n",
    "                                    length_before_new_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([156, 156, 156, 156, 156,  45,  45,  45,  45,  45,  16,  16,  16,  16,\n",
      "         16,  15,  15,  15,  15,  15, 103, 103, 103, 103, 103, 110, 110, 110,\n",
      "        110, 110,  17,  17,  17,  17,  17,   6,   6,   6,   6,   6,   9,   9,\n",
      "          9,   9,   9,  21,  21,  21,  21,  21,  32,  32,  32,  32,  32,  50,\n",
      "         50,  50,  50,  50, 107, 107, 107, 107])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bninception(dim=hidden_dim, pretrained=None)\n",
    "model = torch.nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ### \n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        indices_tuple = mining_func(embeddings, labels)\n",
    "        loss = loss_func(embeddings, labels, indices_tuple)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(epoch, batch_idx, loss, mining_func.num_triplets))\n",
    "\n",
    "### convenient function from pytorch-metric-learning ###\n",
    "def get_all_embeddings(dataset, model):\n",
    "    tester = testers.BaseTester()\n",
    "    return tester.get_all_embeddings(dataset, model)\n",
    "\n",
    "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n",
    "def test(train_set, test_set, model, accuracy_calculator):\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "    print(\"Computing accuracy\")\n",
    "    accuracies = accuracy_calculator.get_accuracy(test_embeddings, \n",
    "                                                  train_embeddings,\n",
    "                                                  test_labels,\n",
    "                                                  train_labels,\n",
    "                                                  False)\n",
    "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n",
    "    return accuracies[\"precision_at_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pytorch-metric-learning stuff ###\n",
    "distance = distances.CosineSimilarity()\n",
    "reducer = reducers.MeanReducer()\n",
    "loss_func = losses.SoftTripleLoss(num_classes=num_classes, \n",
    "                                  embedding_size=hidden_dim, \n",
    "                                  centers_per_class=centers_per_class, \n",
    "                                  la=20, \n",
    "                                  gamma=0.1, \n",
    "                                  margin=0.01).to(device)\n",
    "\n",
    "loss_optimizer = torch.optim.Adam([{\"params\": model.parameters(), \"lr\": 1e-4},\n",
    "                                   {\"params\": loss_func.parameters(), \"lr\": 1e-2}])\n",
    "\n",
    "mining_func = miners.TripletMarginMiner(margin = 0.2, distance = distance, type_of_triplets = \"semi-hard\")\n",
    "accuracy_calculator = AccuracyCalculator(include = (\"precision_at_1\",), k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 5.238691329956055, Number of mined triplets = 14378\n",
      "Epoch 1 Iteration 100: Loss = 5.0792341232299805, Number of mined triplets = 10792\n",
      "Epoch 1 Iteration 200: Loss = 4.540863990783691, Number of mined triplets = 11724\n",
      "Epoch 1 Iteration 300: Loss = 4.045415878295898, Number of mined triplets = 10405\n",
      "Epoch 1 Iteration 400: Loss = 3.2982752323150635, Number of mined triplets = 9695\n",
      "Epoch 1 Iteration 500: Loss = 4.1106157302856445, Number of mined triplets = 9902\n",
      "Epoch 1 Iteration 600: Loss = 2.7585184574127197, Number of mined triplets = 8452\n",
      "Epoch 1 Iteration 700: Loss = 2.9367265701293945, Number of mined triplets = 8601\n",
      "Epoch 1 Iteration 800: Loss = 2.873548984527588, Number of mined triplets = 8519\n",
      "Epoch 1 Iteration 900: Loss = 2.69873046875, Number of mined triplets = 6418\n",
      "Epoch 1 Iteration 1000: Loss = 1.5383989810943604, Number of mined triplets = 5469\n",
      "Epoch 1 Iteration 1100: Loss = 1.411964774131775, Number of mined triplets = 4992\n",
      "Epoch 1 Iteration 1200: Loss = 1.6123805046081543, Number of mined triplets = 6836\n",
      "Epoch 1 Iteration 1300: Loss = 1.008882761001587, Number of mined triplets = 5151\n",
      "Epoch 1 Iteration 1400: Loss = 0.6148874163627625, Number of mined triplets = 4971\n",
      "Epoch 1 Iteration 1500: Loss = 0.5323655605316162, Number of mined triplets = 4776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:19<00:00, 13.35it/s]\n",
      "100%|██████████| 252/252 [00:19<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing accuracy\n",
      "Test set accuracy (Precision@1) = 0.46412139711901546\n",
      "Epoch 2 Iteration 0: Loss = 0.6029092073440552, Number of mined triplets = 4709\n",
      "Epoch 2 Iteration 100: Loss = 0.6121525764465332, Number of mined triplets = 4493\n",
      "Epoch 2 Iteration 200: Loss = 0.40242645144462585, Number of mined triplets = 3826\n",
      "Epoch 2 Iteration 300: Loss = 0.5477001667022705, Number of mined triplets = 4915\n",
      "Epoch 2 Iteration 400: Loss = 0.3680006265640259, Number of mined triplets = 5314\n",
      "Epoch 2 Iteration 500: Loss = 0.39715105295181274, Number of mined triplets = 4742\n",
      "Epoch 2 Iteration 600: Loss = 0.2457796186208725, Number of mined triplets = 3972\n",
      "Epoch 2 Iteration 700: Loss = 0.3505677580833435, Number of mined triplets = 4123\n",
      "Epoch 2 Iteration 800: Loss = 0.19687652587890625, Number of mined triplets = 5007\n",
      "Epoch 2 Iteration 900: Loss = 0.22015593945980072, Number of mined triplets = 2672\n",
      "Epoch 2 Iteration 1000: Loss = 0.23871999979019165, Number of mined triplets = 4215\n",
      "Epoch 2 Iteration 1100: Loss = 0.19763442873954773, Number of mined triplets = 3224\n",
      "Epoch 2 Iteration 1200: Loss = 0.32316115498542786, Number of mined triplets = 3876\n",
      "Epoch 2 Iteration 1300: Loss = 0.0776078850030899, Number of mined triplets = 2693\n",
      "Epoch 2 Iteration 1400: Loss = 0.1631735861301422, Number of mined triplets = 4888\n"
     ]
    }
   ],
   "source": [
    "### pytorch-metric-learning stuff ###\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(model, loss_func, mining_func, device, train_loader, loss_optimizer, epoch)\n",
    "    knn_acc = test(train_data, test_data, model, accuracy_calculator)\n",
    "    if epoch % 50 == 0 or epoch == 1:\n",
    "        torch.save(model.state_dict(), os.path.join(result_dir, '{}_epoch{}_knnAcc{:.4f}.pt'.format(exp_name, epoch, knn_acc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
