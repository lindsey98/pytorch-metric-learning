{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  1 16:07:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 28%   39C    P2    38W / 250W |   2979MiB / 12066MiB |     44%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN V             Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 28%   41C    P2    40W / 250W |   3077MiB / 12066MiB |     17%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   3662931      C   ...a3/envs/mypy37/bin/python     2975MiB |\n",
      "|    1   N/A  N/A   3662931      C   ...a3/envs/mypy37/bin/python     3073MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/l/liny/ruofan/pytorch-metric-learning/src')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_metric_learning.models import bninception\n",
    "from pytorch_metric_learning import samplers\n",
    "from pytorch_metric_learning.datasets.Cub2011 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "num_classes = 200\n",
    "hidden_dim = 512\n",
    "centers_per_class = 5\n",
    "result_dir = './log'\n",
    "exp_name = 'Cub2011'\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = Cub2011(root='pytorch_metric_learning/datasets/Cub2011/', \n",
    "                     train=True, \n",
    "                     transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Cub2011(root='pytorch_metric_learning/datasets/Cub2011/', \n",
    "                     train=False, \n",
    "                     transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = samplers.MPerClassSampler(train_data.labels, \n",
    "                                    m=5, \n",
    "                                    length_before_new_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([167, 167, 167, 167, 167, 133, 133, 133, 133, 133,  71,  71,  71,  71,\n",
      "         71, 144, 144, 144, 144, 144, 194, 194, 194, 194, 194,  60,  60,  60,\n",
      "         60,  60,  28,  28,  28,  28,  28, 151, 151, 151, 151, 151, 170, 170,\n",
      "        170, 170, 170,  20,  20,  20,  20,  20, 123, 123, 123, 123, 123, 115,\n",
      "        115, 115, 115, 115, 132, 132, 132, 132])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bninception(dim=hidden_dim, pretrained=None)\n",
    "model = torch.nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ### \n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        indices_tuple = mining_func(embeddings, labels)\n",
    "        loss = loss_func(embeddings, labels, indices_tuple)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(epoch, batch_idx, loss, mining_func.num_triplets))\n",
    "\n",
    "### convenient function from pytorch-metric-learning ###\n",
    "def get_all_embeddings(dataset, model):\n",
    "    tester = testers.BaseTester()\n",
    "    return tester.get_all_embeddings(dataset, model)\n",
    "\n",
    "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n",
    "def test(train_set, test_set, model, accuracy_calculator):\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "    print(\"Computing accuracy\")\n",
    "    accuracies = accuracy_calculator.get_accuracy(test_embeddings, \n",
    "                                                  train_embeddings,\n",
    "                                                  test_labels,\n",
    "                                                  train_labels,\n",
    "                                                  False)\n",
    "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n",
    "    return accuracies[\"precision_at_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pytorch-metric-learning stuff ###\n",
    "distance = distances.CosineSimilarity()\n",
    "reducer = reducers.MeanReducer()\n",
    "loss_func = losses.SoftTripleLoss(num_classes=num_classes, \n",
    "                                  embedding_size=hidden_dim, \n",
    "                                  centers_per_class=centers_per_class, \n",
    "                                  la=20, \n",
    "                                  gamma=0.1, \n",
    "                                  margin=0.01).to(device)\n",
    "\n",
    "loss_optimizer = torch.optim.Adam([{\"params\": model.parameters(), \"lr\": 1e-4},\n",
    "                                   {\"params\": loss_func.parameters(), \"lr\": 1e-2}])\n",
    "\n",
    "mining_func = miners.TripletMarginMiner(margin = 0.2, distance = distance, type_of_triplets = \"semi-hard\")\n",
    "accuracy_calculator = AccuracyCalculator(include = (\"precision_at_1\",), k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 5.0204339027404785, Number of mined triplets = 13557\n",
      "Epoch 1 Iteration 100: Loss = 4.598340034484863, Number of mined triplets = 10376\n",
      "Epoch 1 Iteration 200: Loss = 4.502689361572266, Number of mined triplets = 10363\n",
      "Epoch 1 Iteration 300: Loss = 3.1398725509643555, Number of mined triplets = 9010\n"
     ]
    }
   ],
   "source": [
    "### pytorch-metric-learning stuff ###\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(model, loss_func, mining_func, device, train_loader, loss_optimizer, epoch)\n",
    "    knn_acc = test(train_data, test_data, model, accuracy_calculator)\n",
    "    if epoch % 50 == 0 or epoch == 1:\n",
    "        torch.save(model.state_dict(), os.path.join(result_dir, '{}_epoch{}_knnAcc{:.4f}.pt'.format(exp_name, epoch, knn_acc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
