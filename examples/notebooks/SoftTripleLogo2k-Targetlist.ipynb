{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  1 10:37:20 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 28%   39C    P2    51W / 250W |   6319MiB / 12066MiB |     25%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN V             Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 28%   40C    P2    43W / 250W |   2975MiB / 12066MiB |     22%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   3992545      C   ...a3/envs/mypy37/bin/python     6315MiB |\n",
      "|    1   N/A  N/A   3992545      C   ...a3/envs/mypy37/bin/python     2971MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/l/liny/ruofan/pytorch-metric-learning/src')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1, 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_metric_learning.models import bninception\n",
    "from pytorch_metric_learning import samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "result_dir = './log'\n",
    "exp_name = 'targetlist'\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = GetLoader(data_root='/home/l/liny/ruofan/lightly/datasets/targetlist/train/', \n",
    "                           data_list='/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/train_targets.txt', \n",
    "                           label_dict='/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/target_dict.json',\n",
    "                           transform=train_transform)\n",
    "\n",
    "test_data = GetLoader(data_root='/home/l/liny/ruofan/lightly/datasets/targetlist/test/', \n",
    "                      data_list='/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/test_targets.txt', \n",
    "                      label_dict='/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/target_dict.json',\n",
    "                      transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = samplers.MPerClassSampler(train_data.labels, \n",
    "                                    m=5, \n",
    "                                    length_before_new_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data, target in train_loader:\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bninception(dim=512, pretrained=None)\n",
    "model = torch.nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ### \n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        indices_tuple = mining_func(embeddings, labels)\n",
    "        loss = loss_func(embeddings, labels, indices_tuple)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(epoch, batch_idx, loss, mining_func.num_triplets))\n",
    "\n",
    "### convenient function from pytorch-metric-learning ###\n",
    "def get_all_embeddings(dataset, model):\n",
    "    tester = testers.BaseTester()\n",
    "    return tester.get_all_embeddings(dataset, model)\n",
    "\n",
    "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n",
    "def test(train_set, test_set, model, accuracy_calculator):\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "    print(\"Computing accuracy\")\n",
    "    accuracies = accuracy_calculator.get_accuracy(test_embeddings, \n",
    "                                                  train_embeddings,\n",
    "                                                  test_labels,\n",
    "                                                  train_labels,\n",
    "                                                  False)\n",
    "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n",
    "    return accuracies[\"precision_at_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pytorch-metric-learning stuff ###\n",
    "distance = distances.CosineSimilarity()\n",
    "reducer = reducers.MeanReducer()\n",
    "loss_func = losses.SoftTripleLoss(num_classes=277, \n",
    "                                  embedding_size=512, \n",
    "                                  centers_per_class=5, \n",
    "                                  la=20, \n",
    "                                  gamma=0.1, \n",
    "                                  margin=0.01).to(device)\n",
    "\n",
    "loss_optimizer = torch.optim.Adam([{\"params\": model.parameters(), \"lr\": 1e-4},\n",
    "                                   {\"params\": loss_func.parameters(), \"lr\": 1e-2}])\n",
    "\n",
    "mining_func = miners.TripletMarginMiner(margin = 0.2, distance = distance, type_of_triplets = \"semi-hard\")\n",
    "accuracy_calculator = AccuracyCalculator(include = (\"precision_at_1\",), k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 5.140124320983887, Number of mined triplets = 13326\n",
      "Epoch 1 Iteration 100: Loss = 3.8162100315093994, Number of mined triplets = 7420\n",
      "Epoch 1 Iteration 200: Loss = 2.860548496246338, Number of mined triplets = 7212\n",
      "Epoch 1 Iteration 300: Loss = 2.2279305458068848, Number of mined triplets = 6073\n",
      "Epoch 1 Iteration 400: Loss = 1.239741563796997, Number of mined triplets = 4349\n",
      "Epoch 1 Iteration 500: Loss = 1.0321711301803589, Number of mined triplets = 3183\n",
      "Epoch 1 Iteration 600: Loss = 1.0425498485565186, Number of mined triplets = 4776\n",
      "Epoch 1 Iteration 700: Loss = 0.6735363602638245, Number of mined triplets = 3626\n",
      "Epoch 1 Iteration 800: Loss = 0.4943087697029114, Number of mined triplets = 4728\n",
      "Epoch 1 Iteration 900: Loss = 0.14444376528263092, Number of mined triplets = 4051\n",
      "Epoch 1 Iteration 1000: Loss = 0.13914911448955536, Number of mined triplets = 6326\n",
      "Epoch 1 Iteration 1100: Loss = 0.08922342956066132, Number of mined triplets = 5048\n",
      "Epoch 1 Iteration 1200: Loss = 0.14599865674972534, Number of mined triplets = 5001\n",
      "Epoch 1 Iteration 1300: Loss = 0.0377560555934906, Number of mined triplets = 6092\n",
      "Epoch 1 Iteration 1400: Loss = 0.016913890838623047, Number of mined triplets = 5233\n",
      "Epoch 1 Iteration 1500: Loss = 0.030525818467140198, Number of mined triplets = 4861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:10<00:00,  7.21it/s]\n",
      "100%|██████████| 19/19 [00:08<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing accuracy\n",
      "Test set accuracy (Precision@1) = 0.5810810951516032\n",
      "Epoch 2 Iteration 0: Loss = 0.032736364752054214, Number of mined triplets = 6161\n",
      "Epoch 2 Iteration 100: Loss = 0.02631489746272564, Number of mined triplets = 4329\n",
      "Epoch 2 Iteration 200: Loss = 0.033279165625572205, Number of mined triplets = 5718\n",
      "Epoch 2 Iteration 300: Loss = 0.031628288328647614, Number of mined triplets = 4197\n",
      "Epoch 2 Iteration 400: Loss = 0.010961171239614487, Number of mined triplets = 5924\n",
      "Epoch 2 Iteration 500: Loss = 0.012311478145420551, Number of mined triplets = 5192\n",
      "Epoch 2 Iteration 600: Loss = 0.0054053086787462234, Number of mined triplets = 4318\n",
      "Epoch 2 Iteration 700: Loss = 0.004264707677066326, Number of mined triplets = 5287\n",
      "Epoch 2 Iteration 800: Loss = 0.00423540361225605, Number of mined triplets = 4576\n",
      "Epoch 2 Iteration 900: Loss = 0.0050986148416996, Number of mined triplets = 7239\n",
      "Epoch 2 Iteration 1000: Loss = 0.01993974670767784, Number of mined triplets = 6851\n"
     ]
    }
   ],
   "source": [
    "### pytorch-metric-learning stuff ###\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(model, loss_func, mining_func, device, train_loader, loss_optimizer, epoch)\n",
    "    knn_acc = test(train_data, test_data, model, accuracy_calculator)\n",
    "    if epoch % 20 == 0 or epoch == 1:\n",
    "        torch.save(model.state_dict(), \n",
    "                   os.path.join(result_dir, '{}_epoch{}_knnAcc{:.4f}.pt'.format(exp_name, epoch, knn_acc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
